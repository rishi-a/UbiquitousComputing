{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will brifly understand how backpropagation happens in a maxpooling layer. <br>For this tiny examples, I took two matrix (can be thought of as an image) as an input with the sum of matrix as the output. Our objective is to learn the weights such that the sum of each of the matrix can be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Warning: We need numpy. 1.15 for the skimage to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np,sys\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "import skimage.measure\n",
    "from scipy.signal import convolve2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the output for a single pass of the feed forward network. We expect the error to be very high comapred to the ground truth values.\n",
    "![Image of How Forward Pass Was Implemented](forward.jpg \"Text to show on mouseover\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the activation functions that we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7839)\n",
    "def ReLu(x):\n",
    "    mask = (x>0) * 1.0 \n",
    "    return x * mask\n",
    "def d_ReLu(x):\n",
    "    mask = (x>0) * 1.0 \n",
    "    return  mask\n",
    "\n",
    "def arctan(x):\n",
    "    return np.arctan(x)\n",
    "def d_arctan(x):\n",
    "    return 1 / (1+ x ** 2)\n",
    "\n",
    "def log(x):\n",
    "    return 1 / ( 1 + np.exp( -1 *x))\n",
    "def d_log(x):\n",
    "    return log(x) * (1 - log(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have two random inputs with the sum of all the pixels as the ground truth output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input X1 = (6, 6)\n",
      "Shape of input X2 = (6, 6)\n",
      "Ground truth of output = \n",
      "[[ 1.53377621]\n",
      " [-1.48765509]]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array([\n",
    "    [1,1,0,1,0,1],\n",
    "    [1,1,0,1,0,1],\n",
    "    [1,1,0,1,0,1],\n",
    "    [1,1,1,1,0,1],\n",
    "    [1,1,1,1,0,1],\n",
    "    [1,1,1,1,0,1]    \n",
    "])\n",
    "print(\"Shape of input X1 = {}\".format(x1.shape))\n",
    "x2 = np.array([\n",
    "    [-1,0,-1,0,0,1],\n",
    "    [-1,0,-1,0,0,1],\n",
    "    [-1,0,-1,1,0,1],\n",
    "    [-1,-1,-1,0,0,-1],\n",
    "    [-1,0,-1,0,0,-1],\n",
    "    [-1,0,-1,0,0,-1]    \n",
    "])\n",
    "print(\"Shape of input X2 = {}\".format(x2.shape))\n",
    "X = np.array([x1,x2])\n",
    "y = np.array([\n",
    "    [arctan(x1.sum())],\n",
    "    [arctan(x2.sum())]\n",
    "])\n",
    "print(\"Ground truth of output = \\n{}\".format(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set the weights and initialize the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 1000\n",
    "learing_rate = 0.1\n",
    "\n",
    "w1 = np.random.randn(3,3) * 2.27\n",
    "w2 = np.random.randn(4,1)* 6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward pass is implemented below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ground Truth -----\n",
      "[[ 1.53377621 -1.48765509]]\n",
      "--- Before Training -----\n",
      "[1.54101825 1.56057584]\n"
     ]
    }
   ],
   "source": [
    "prediction = np.array([])\n",
    "for image_index in range(len(X)):\n",
    "    \n",
    "    current_image = X[image_index]\n",
    "    current_label = y[image_index]\n",
    "\n",
    "    l1 = convolve2d(current_image,w1,mode='valid')\n",
    "    l1A = ReLu(l1)\n",
    "    l1M = skimage.measure.block_reduce(l1A, (2,2), np.max)\n",
    "\n",
    "    l2IN = np.reshape(l1M,(1,4))\n",
    "    l2 = l2IN.dot(w2)\n",
    "    l2A = arctan(l2)\n",
    "\n",
    "    prediction = np.append(prediction,l2A)\n",
    "\n",
    "print(\"--- Ground Truth -----\")\n",
    "print(y.T)\n",
    "print(\"--- Before Training -----\")\n",
    "print(prediction.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model. \n",
    "![Image of How Backprop Was Implemented](backward.jpg \"Text to show on mouseover\").<br>\n",
    "**Note:** I found the code for backprop online. But the image above explains the code. The idea is to resize a matrix so that we can perform backpropagation over maxpolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(num_epoch):\n",
    "    \n",
    "    for image_index in range(len(X)):\n",
    "        \n",
    "        current_image = X[image_index]\n",
    "        current_label = y[image_index]\n",
    "\n",
    "        l1 = convolve2d(current_image,w1,mode='valid')\n",
    "        l1A = ReLu(l1)\n",
    "        l1M = skimage.measure.block_reduce(l1A, (2,2), np.max)\n",
    "\n",
    "        l2IN = np.reshape(l1M,(1,4))\n",
    "        l2 = l2IN.dot(w2)\n",
    "        l2A = arctan(l2)\n",
    "\n",
    "        cost = np.square(l2A - current_label).sum() * 0.5\n",
    "        # print(\"Current Iter: \", iter, \" current cost :\", cost ,end='\\r')\n",
    "\n",
    "        grad_2_part_1 = l2A - current_label\n",
    "        grad_2_part_2 = d_arctan(l2)\n",
    "        grad_2_part_3 = l2IN\n",
    "        grad_2 = grad_2_part_3.T.dot(grad_2_part_1 * grad_2_part_2)\n",
    "\n",
    "        grad_1_part_1 =  np.reshape((grad_2_part_1 * grad_2_part_2).dot(w2.T),(2,2))\n",
    "        grad_1_mask =  np.equal(l1A, l1M.repeat(2, axis=0).repeat(2, axis=1)).astype(int) \n",
    "        grad_1_window = grad_1_mask * grad_1_part_1.repeat(2, axis=0).repeat(2, axis=1) \n",
    "        grad_1_part_2 = d_ReLu(l1)\n",
    "        grad_1_part_3 = current_image\n",
    "        grad_1 = np.rot90(convolve2d(grad_1_part_3,np.rot90(grad_1_window *grad_1_part_2,2 ),mode='valid'),2)\n",
    "\n",
    "        w2 = w2 - learing_rate * grad_2\n",
    "        w1 = w1 - learing_rate * grad_1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on the learned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ground Truth -----\n",
      "[[ 1.53377621 -1.48765509]]\n",
      "--- After Training -----\n",
      "[1.54102975 1.56028047]\n"
     ]
    }
   ],
   "source": [
    "prediction = np.array([])\n",
    "for image_index in range(len(X)):\n",
    "    \n",
    "    current_image = X[image_index]\n",
    "    current_label = y[image_index]\n",
    "\n",
    "    l1 = convolve2d(current_image,w1,mode='valid')\n",
    "    l1A = ReLu(l1)\n",
    "    l1M = skimage.measure.block_reduce(l1A, (2,2), np.max)\n",
    "\n",
    "    l2IN = np.reshape(l1M,(1,4))\n",
    "    l2 = l2IN.dot(w2)\n",
    "    l2A = arctan(l2)\n",
    "\n",
    "    prediction = np.append(prediction,l2A)\n",
    "\n",
    "print(\"--- Ground Truth -----\")\n",
    "print(y.T)\n",
    "print(\"--- After Training -----\")\n",
    "print(prediction.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the complete story. Backpropagation via maxpolling layer would not be possible unless we change the dimension of the weight matrix from 4*1 to 4*4. To do that, we revisit the forward pass as shown in the image below\n",
    "![Image of How Forward Pass Was Used For Implementing The BackProp in the Maxpooling Layer](all.jpg \"Text to show on mouseover\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
