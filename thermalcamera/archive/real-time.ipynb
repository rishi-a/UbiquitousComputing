{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "375abfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import signal as sp\n",
    "from mss import mss\n",
    "from PIL import Image\n",
    "\n",
    "# makes plot pop out\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "641877e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fft(s, sampling_rate, n = None, scale_amplitudes = True):\n",
    "    '''Computes an FFT on signal s using numpy.fft.fft.\n",
    "    \n",
    "       Parameters:\n",
    "        s (np.array): the signal\n",
    "        sampling_rate (num): sampling rate\n",
    "        n (integer): If n is smaller than the length of the input, the input is cropped. If n is \n",
    "            larger, the input is padded with zeros. If n is not given, the length of the input signal \n",
    "            is used (i.e., len(s))\n",
    "        scale_amplitudes (boolean): If true, the spectrum amplitudes are scaled by 2/len(s)\n",
    "    '''\n",
    "    if n == None:\n",
    "        n = len(s)\n",
    "        \n",
    "    fft_result = np.fft.fft(s, n)\n",
    "    num_freq_bins = len(fft_result)\n",
    "    fft_freqs = np.fft.fftfreq(num_freq_bins, d = 1 / sampling_rate)\n",
    "    half_freq_bins = num_freq_bins // 2\n",
    " \n",
    "    fft_freqs = fft_freqs[:half_freq_bins]\n",
    "    fft_result = fft_result[:half_freq_bins]\n",
    "    fft_amplitudes = np.abs(fft_result)\n",
    "    \n",
    "    if scale_amplitudes is True:\n",
    "        fft_amplitudes = 2 * fft_amplitudes / (len(s))\n",
    "    \n",
    "    return (fft_freqs, fft_amplitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d85c1908",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     tom, thres \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(mask, \u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY)\n\u001b[1;32m     66\u001b[0m     contours \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindContours(thres, cv2\u001b[38;5;241m.\u001b[39mRETR_EXTERNAL, cv2\u001b[38;5;241m.\u001b[39mCHAIN_APPROX_SIMPLE)\n\u001b[0;32m---> 67\u001b[0m     x,y,w,h \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mboundingRect(\u001b[43mcontours\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     68\u001b[0m     crop \u001b[38;5;241m=\u001b[39m masked_data[y:y\u001b[38;5;241m+\u001b[39mh,x:x\u001b[38;5;241m+\u001b[39mw]\n\u001b[1;32m     71\u001b[0m sumofPixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(crop[:,:])\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# version 0.2\n",
    "#mp_face_mesh = mp.solutions.face_mesh\n",
    "#face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False) #meant for video feed\n",
    "\n",
    "def select_point(event, x ,y, flags, param):\n",
    "    global point, point_selected, old_points;\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        point = (x,y)\n",
    "        point_selected=True\n",
    "        old_points = np.array([[x,y,]], dtype=np.float32)\n",
    "        \n",
    "\n",
    "sct = mss()\n",
    "bounding_box = {'top': 355, 'left': 100, 'width': 200, 'height': 200}\n",
    "sct_img = sct.grab(bounding_box)\n",
    "color_img = np.array(sct_img)\n",
    "old_gray = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        \n",
    "# lucas kanade params\n",
    "lk_param = dict(winSize=(100,100), maxLevel=64, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10,0.03))\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"Frame\")\n",
    "cv2.setMouseCallback(\"Frame\", select_point)\n",
    "point_selected = False;\n",
    "point = ()   \n",
    "old_points = np.array([[]])\n",
    "rrSignal = []\n",
    "\n",
    "# hook the function to be called in case of mouse click\n",
    "cv2.setMouseCallback(\"Frame\", select_point)\n",
    "\n",
    "while True:\n",
    "    sumofPixels=0\n",
    "    sct_img = sct.grab(bounding_box)\n",
    "    color_img = np.array(sct_img)\n",
    "    gray_frame = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # get the size of the frame\n",
    "    height, width, channel = color_img.shape\n",
    "    \n",
    "    # create a all-zeros mask, we are doing this to get all the pixels covered by the circle\n",
    "    mask = np.zeros((height, width), np.uint8)\n",
    "    \n",
    "    crop=np.zeros((7,7));\n",
    "    \n",
    "    if point_selected is True:\n",
    "        cv2.circle(color_img, point, 4, (0, 5, 255), -1) #BGR Format\n",
    "        \n",
    "        new_points, status, error = cv2.calcOpticalFlowPyrLK(old_gray, gray_frame, old_points, None, **lk_param) \n",
    "        old_gray = gray_frame.copy()\n",
    "        old_points = new_points\n",
    "        x,y = new_points.ravel()\n",
    "        \n",
    "        circleRadius = 5\n",
    "        # draw the moving pint as optics flow\n",
    "        cv2.circle(color_img, (int(x),int(y)),circleRadius,(255,0,0),-1)\n",
    "        \n",
    "        # create the circle with new point over the mask as well\n",
    "        circle_mask = cv2.circle(mask, (int(x), int(y)),circleRadius,(255,0,0),-1)\n",
    "        masked_data = cv2.bitwise_and(gray_frame,gray_frame,mask=circle_mask)\n",
    "        \n",
    "        # code to get all pixel location inside the ROI in the optical flow\n",
    "        tom, thres = cv2.threshold(mask, 1,255, cv2.THRESH_BINARY)\n",
    "        contours = cv2.findContours(thres, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        x,y,w,h = cv2.boundingRect(contours[0][0])\n",
    "        crop = masked_data[y:y+h,x:x+w]\n",
    "        \n",
    "        \n",
    "    sumofPixels = np.sum(crop[:,:])\n",
    "    rrSignal.append(sumofPixels)\n",
    "    \n",
    "    if(len(rrSignal)>=120):\n",
    "        size = 15\n",
    "        window = sp.gaussian(M=size, std=6)\n",
    "        window /= window.sum()\n",
    "        filteredA = np.convolve(np.array(rrSignal[-120:]), window, mode='same')\n",
    "\n",
    "        F,A = compute_fft(filteredA, 25, n = None, scale_amplitudes = True)\n",
    "        highestFreq = F[np.argmax(A[1:])+1]\n",
    "\n",
    "        #print(\"Breathing Rate = {:.2f}\".format(highestFreq*60))  \n",
    "\n",
    "        plt.plot(rrSignal[-120:], 'b-')\n",
    "        plt.title(\"Respiration Rate\",fontdict={'fontsize': 20})\n",
    "        plt.xlabel('Frame Number')\n",
    "        plt.show()\n",
    "        plt.pause(0.001)\n",
    "\n",
    "        plt.clf()\n",
    "\n",
    "    # Create the haar cascade\n",
    "    #noseCascade = cv2.CascadeClassifier(\"haarcascade_mcs_nose.xml\")\n",
    "    #nose = noseCascade.detectMultiScale(gray)\n",
    "                        \n",
    "    #for (ex,ey,ew,eh) in nose:\n",
    "    #    cv2.rectangle(color_img,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "    \n",
    "    cv2.imshow('Frame', color_img)\n",
    "    if (cv2.waitKey(1) & 0xFF) == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0409529c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
