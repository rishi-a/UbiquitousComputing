{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-2-5819601ace90>\", line 91, in readIntensity\n",
      "    frame = cv2.resize(frame,(-1,-1), fx=scaleFactor, fy=scaleFactor)\n",
      "cv2.error: C:\\ci\\opencv_1512688052760\\work\\modules\\imgproc\\src\\resize.cpp:3289: error: (-215) ssize.width > 0 && ssize.height > 0 in function cv::resize\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5819601ace90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurFrame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[0mbb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcropBoxBounds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[0mROI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[0mgetHR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from scipy import signal\n",
    "import threading\n",
    "\n",
    "import scipy.signal as sig\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "\n",
    "def applyFF(data, sampleFreq):\n",
    "    if sampleFreq > 3:\n",
    "        sos = sig.iirdesign([.66, 3.0], [.5, 4.0], 1.0, 40.0, fs=sampleFreq, output='sos')\n",
    "        return sig.sosfiltfilt(sos, data)\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def getFaceXYHWAndEyeXYHW(im):\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Only take one face, the first\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(faces) < 1:\n",
    "        return None\n",
    "    (x, y, w, h) = faces[0]\n",
    "\n",
    "    # Crop out faces and detect eyes in that window.\n",
    "    roi_gray = gray[y:y + h, x:x + w]\n",
    "    eyes, numDetects = eye_cascade.detectMultiScale2(roi_gray, minNeighbors=10)\n",
    "    if len(numDetects) < 2:\n",
    "        return None\n",
    "\n",
    "    # Change eye coords to be in image coordinates instead of face coordinates\n",
    "    eyes[0][0] += x\n",
    "    eyes[1][0] += x\n",
    "    eyes[0][1] += y\n",
    "    eyes[1][1] += y\n",
    "\n",
    "    return [faces[0], eyes[0], eyes[1]]\n",
    "\n",
    "def getFace(im):\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Only take one face, the first\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(faces) < 1:\n",
    "        return None\n",
    "\n",
    "    return faces[0]\n",
    "\n",
    "\n",
    "dataLen = 120\n",
    "camTimes = [0]*dataLen\n",
    "intensities = []\n",
    "x = list(range(len(intensities)))\n",
    "\n",
    "\n",
    "def getHR():\n",
    "    fs = 1 / (sum(camTimes) / dataLen)\n",
    "    tmpIntens = sig.detrend(applyFF(intensities, fs))\n",
    "    freqs, pows = signal.welch(tmpIntens, fs=fs, nperseg=256)\n",
    "    bpm = round(freqs[np.argmax(pows)] * 60, 2)\n",
    "    print(\"output BPM: \", bpm, fs)\n",
    "    return bpm\n",
    "\n",
    "\n",
    "\n",
    "def getHeadboxFromHead(face):\n",
    "    return face[0] + face[2] // 4, face[1] + face[3] // 2, face[0] + 3 * face[\n",
    "        2] // 4, face[1] + face[3] // 2 + 50\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def readIntensity(intensities, curFrame, cropBoxBounds):\n",
    "    now = 0\n",
    "\n",
    "    eyeleft = 0\n",
    "    headTop = 0\n",
    "    eyeright = 0\n",
    "    eyeTop = 0\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        scaleFactor = 0.4\n",
    "        frame = cv2.resize(frame,(-1,-1), fx=scaleFactor, fy=scaleFactor)\n",
    "\n",
    "        # tmp = getFaceXYHWAndEyeXYHW(frame) # Haar outputs [x, y, w, h] format\n",
    "        face = getFace(frame)\n",
    "        if face is not None:\n",
    "        # if tmp != None:\n",
    "            # face, eye1, eye2 = tmp\n",
    "            # eyeleft, headTop, eyeright, eyeTop\\\n",
    "            # tmpHeadbox = getHeadbox(face, eye1, eye2)\n",
    "            tmpHeadbox = getHeadboxFromHead(face)\n",
    "\n",
    "            a = .4\n",
    "            eyeleft = int(tmpHeadbox[0]*a + (1-a)*eyeleft)\n",
    "            headTop = int(tmpHeadbox[1]*a + (1-a)*headTop)\n",
    "            eyeright = int(tmpHeadbox[2]*a + (1-a)*eyeright)\n",
    "            eyeTop = int(tmpHeadbox[3]*a + (1-a)*eyeTop)\n",
    "\n",
    "\n",
    "            ROI = frame[headTop:eyeTop, eyeleft:eyeright, 1]\n",
    "            intensity = ROI.mean()\n",
    "            # intensity = np.median(ROI) # works, but quite chunky.\n",
    "\n",
    "            intensities.append(intensity)\n",
    "\n",
    "            # Draw the forehead box:\n",
    "            curFrame[0] = cv2.rectangle(frame, (eyeleft, headTop),\n",
    "                                        (eyeright, eyeTop), (0, 255, 0), 1)\n",
    "            cropBoxBounds[0] = [headTop + 2, eyeTop - 2, eyeleft + 2, eyeright - 2]\n",
    "\n",
    "            if (len(intensities) > dataLen):\n",
    "                intensities.pop(0)\n",
    "\n",
    "            camTimes.append(time.time() - now)\n",
    "            now = time.time()\n",
    "            camTimes.pop(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cropBoxBounds = [0]\n",
    "curFrame = [0]\n",
    "t1 = threading.Thread(target = readIntensity, daemon=True, args=(intensities, curFrame, cropBoxBounds))\n",
    "t1.start()\n",
    "\n",
    "\n",
    "time.sleep(1)\n",
    "while True:\n",
    "    frame = curFrame[0]\n",
    "    bb = cropBoxBounds[0]\n",
    "    ROI = frame[bb[0]:bb[1], bb[2]:bb[3], 1]\n",
    "    getHR()\n",
    "\n",
    "    cv2.imshow(\"yea\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
